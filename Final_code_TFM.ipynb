{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Code - GAIA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, average_precision_score, precision_recall_curve\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Reshape\n",
    "from tensorflow.keras import Sequential\n",
    "import time\n",
    "import numpy as np\n",
    "# SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Cluster Centroids \n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "# Model 1 \n",
    "from sklearn.ensemble import GradientBoostingClassifier # model 1 \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb # model 2\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # model 3\n",
    "from sklearn.ensemble import RandomForestClassifier # model 4 \n",
    "from sklearn import svm # model 5 \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression # model 6\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV # Grid Search \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to open the final table obtained from GAIA pre-processing step. The final table is made up by 8 columns, in which the column \"Class\" represents the presence/absence of strains.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and change columns names: \n",
    "data = pd.read_excel('final.xlsm', header=None)\n",
    "data.columns =['Strain_ID', 'Genome_length', 'Ratio_1kbp_bins_covered', 'Ratio_GC-content_uncovered_bins', 'Ratio_N-content_uncovered_bins', 'Reads_mapped', 'Total_reads', 'Class']\n",
    "# Drop the Strain_ID column, we are not interested in it: \n",
    "data = data.drop(['Strain_ID'], axis=1)\n",
    "# Normalize columns except Class column: \n",
    "sc = StandardScaler()\n",
    "data[['Genome_length', 'Ratio_1kbp_bins_covered', 'Ratio_GC-content_uncovered_bins', 'Ratio_N-content_uncovered_bins', 'Reads_mapped', 'Total_reads']] = sc.fit_transform(data[['Genome_length', 'Ratio_1kbp_bins_covered', 'Ratio_GC-content_uncovered_bins', 'Ratio_N-content_uncovered_bins', 'Reads_mapped', 'Total_reads']])\n",
    "\n",
    "\n",
    "# 1. Prepare data: with this function we divide the dataset into X and y (y=Class, variable of interest). \n",
    "# Then, we split the data into train and test (20% will be the test): \n",
    "\n",
    "def prepare_data(data,random_state=12):\n",
    "    X = data.drop('Class', axis=1)\n",
    "    y = data['Class']\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    dftrain = [xtrain, ytrain]\n",
    "    dftest = [xtest, ytest]\n",
    "    return pd.concat(dftrain, axis=1), pd.concat(dftest, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.228558</td>\n",
       "      <td>-0.219520</td>\n",
       "      <td>1.078705</td>\n",
       "      <td>-0.168407</td>\n",
       "      <td>-0.117813</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.039962</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.485007</td>\n",
       "      <td>-0.154483</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075952</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.245584</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.590566</td>\n",
       "      <td>-0.168305</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.608627</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.683660</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genome_length  Ratio_1kbp_bins_covered  Ratio_GC-content_uncovered_bins  \\\n",
       "0       0.228558                -0.219520                         1.078705   \n",
       "1       4.039962                -0.220521                         0.485007   \n",
       "2       0.075952                -0.220521                         0.696596   \n",
       "3       2.245584                -0.220521                         0.590566   \n",
       "4       0.608627                -0.220521                         0.683660   \n",
       "\n",
       "   Ratio_N-content_uncovered_bins  Reads_mapped  Total_reads  Class  \n",
       "0                       -0.168407     -0.117813    -0.420667      0  \n",
       "1                       -0.154483     -0.117818    -0.420667      0  \n",
       "2                       -0.168520     -0.117818    -0.420667      0  \n",
       "3                       -0.168305     -0.117818    -0.420667      0  \n",
       "4                       -0.168520     -0.117818    -0.420667      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of the 2 classes: presence (1) and absence (0) of strains: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1352482e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Class']) # initial distribution of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       605\n",
      "           1       0.94      0.71      0.81        24\n",
      "\n",
      "    accuracy                           0.99       629\n",
      "   macro avg       0.97      0.85      0.90       629\n",
      "weighted avg       0.99      0.99      0.99       629\n",
      "\n",
      "[[604   1]\n",
      " [  7  17]]\n",
      "Accuracy :  0.9872813990461049\n",
      "Sensitivity :  0.9983471074380166\n",
      "Specificity :  0.7083333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       605\n",
      "           1       0.89      0.33      0.48        24\n",
      "\n",
      "    accuracy                           0.97       629\n",
      "   macro avg       0.93      0.67      0.74       629\n",
      "weighted avg       0.97      0.97      0.97       629\n",
      "\n",
      "[[604   1]\n",
      " [ 16   8]]\n",
      "Accuracy :  0.972972972972973\n",
      "Sensitivity :  0.9983471074380166\n",
      "Specificity :  0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       605\n",
      "           1       1.00      0.04      0.08        24\n",
      "\n",
      "    accuracy                           0.96       629\n",
      "   macro avg       0.98      0.52      0.53       629\n",
      "weighted avg       0.96      0.96      0.95       629\n",
      "\n",
      "[[605   0]\n",
      " [ 23   1]]\n",
      "Accuracy :  0.9634340222575517\n",
      "Sensitivity :  1.0\n",
      "Specificity :  0.041666666666666664\n"
     ]
    }
   ],
   "source": [
    "# Testing three models on not balanced data in oerder to check the results\n",
    "\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    \n",
    "# 1. Random Forest Classifier \n",
    "rfc = RandomForestClassifier(n_estimators = 200, random_state = 12)\n",
    "rfc.fit(xtrain, ytrain)\n",
    "pred_rfc = rfc.predict(xtest)\n",
    "\n",
    "print(classification_report(ytest, pred_rfc))\n",
    "print(confusion_matrix(ytest, pred_rfc)) # 485 truepositive and 0 true negative\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm1 = (confusion_matrix(ytest, pred_rfc)) \n",
    "total1 = sum(sum(cm1))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "# 2. SVM\n",
    "SVM = svm.SVC(random_state = 12)\n",
    "SVM.fit(xtrain, ytrain)\n",
    "pred_SVM = SVM.predict(xtest)\n",
    "\n",
    "print(classification_report(ytest, pred_SVM)) # quality of the model\n",
    "print(confusion_matrix(ytest, pred_SVM)) # 485 true positive and 0 true negative \n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm2 = (confusion_matrix(ytest, pred_SVM)) \n",
    "total2=sum(sum(cm2))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy2=(cm2[0,0]+cm2[1,1])/total2\n",
    "print ('Accuracy : ', accuracy2)\n",
    "\n",
    "sensitivity2 = cm2[0,0]/(cm2[0,0]+cm2[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "\n",
    "specificity2 = cm2[1,1]/(cm2[1,0]+cm2[1,1]) # TN / (TN + FP)\n",
    "print('Specificity : ', specificity2)\n",
    "\n",
    "# 3. Logistic Regression\n",
    "logreg = LogisticRegression(solver='lbfgs', random_state = 12)\n",
    "logreg.fit(xtrain, ytrain)\n",
    "pred_logreg = logreg.predict(xtest)\n",
    "\n",
    "print(classification_report(ytest, pred_logreg)) # quality of the model\n",
    "print(confusion_matrix(ytest, pred_logreg)) # 346 true positive and 7 true negative \n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm3 = (confusion_matrix(ytest, pred_logreg)) \n",
    "total3=sum(sum(cm3))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy3=(cm3[0,0]+cm3[1,1])/total3\n",
    "print ('Accuracy : ', accuracy3)\n",
    "\n",
    "sensitivity3 = cm3[0,0]/(cm3[0,0]+cm3[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity3 )\n",
    "\n",
    "specificity3 = cm3[1,1]/(cm3[1,0]+cm3[1,1]) # TN / (TN + FP)\n",
    "print('Specificity : ', specificity3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As showed by the count plot, the distribution of data is imbalanced. This means that we have to try to balance the 2 classes before train the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       567\n",
      "           1       0.98      1.00      0.99       643\n",
      "\n",
      "    accuracy                           0.99      1210\n",
      "   macro avg       0.99      0.99      0.99      1210\n",
      "weighted avg       0.99      0.99      0.99      1210\n",
      "\n",
      "[[555  12]\n",
      " [  1 642]]\n",
      "0.010743801652892562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81       567\n",
      "           1       0.92      0.66      0.77       643\n",
      "\n",
      "    accuracy                           0.79      1210\n",
      "   macro avg       0.81      0.80      0.79      1210\n",
      "weighted avg       0.82      0.79      0.79      1210\n",
      "\n",
      "[[531  36]\n",
      " [220 423]]\n",
      "0.2115702479338843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.93      0.79       567\n",
      "           1       0.91      0.63      0.75       643\n",
      "\n",
      "    accuracy                           0.77      1210\n",
      "   macro avg       0.80      0.78      0.77      1210\n",
      "weighted avg       0.81      0.77      0.77      1210\n",
      "\n",
      "[[528  39]\n",
      " [235 408]]\n",
      "0.22644628099173553\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  F1-score\n",
       "0  Random Forest Classifier      0.99\n",
       "1                       SVM      0.76\n",
       "2       Logistic Regression      0.75"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SMOTE method: oversampling \n",
    "\n",
    "# Defining X and y \n",
    "X = data.drop(['Class'], axis = 1 )\n",
    "y = data['Class']\n",
    "\n",
    "# Resampling with SMOTE algorithm \n",
    "X_smote, y_smote = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Splitting data \n",
    "xtrain_sm, xtest_sm, ytrain_sm, ytest_sm = train_test_split(X_smote, y_smote, test_size=0.2, random_state=12)\n",
    "\n",
    "# Testing the models with SMOTE \n",
    "smote = SMOTE(random_state=12)\n",
    "pipeline = Pipeline([('smote', smote), ('rfc', RandomForestClassifier(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline.fit(xtrain_sm, ytrain_sm) # fitting  \n",
    "pred_smote = pipeline.predict(xtest_sm) # predicting \n",
    "print(classification_report(ytest_sm, pred_smote)) # results\n",
    "print(confusion_matrix(ytest_sm,pred_smote))\n",
    "print(mean_absolute_error(ytest_sm, pred_smote))\n",
    "sns.countplot(pred_smote)\n",
    "\n",
    "# 2 \n",
    "\n",
    "pipeline_svm = Pipeline([('smote', smote), ('svm', svm.SVC(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_svm.fit(xtrain_sm, ytrain_sm) # fitting  \n",
    "pred_smote = pipeline_svm.predict(xtest_sm) # predicting \n",
    "print(classification_report(ytest_sm, pred_smote)) # results\n",
    "print(confusion_matrix(ytest_sm,pred_smote))\n",
    "print(mean_absolute_error(ytest_sm, pred_smote))\n",
    "sns.countplot(pred_smote)\n",
    "\n",
    "# 3\n",
    "\n",
    "pipeline_lr = Pipeline([('smote', smote), ('lr', LogisticRegression(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_lr.fit(xtrain_sm, ytrain_sm) # fitting  \n",
    "pred_smote = pipeline_lr.predict(xtest_sm) # predicting \n",
    "print(classification_report(ytest_sm, pred_smote)) # results\n",
    "print(confusion_matrix(ytest_sm,pred_smote))\n",
    "print(mean_absolute_error(ytest_sm, pred_smote))\n",
    "sns.countplot(pred_smote)\n",
    "\n",
    "final_results = pd.DataFrame({'Model' : ['Random Forest Classifier', 'SVM', 'Logistic Regression'], 'F1-score' : [0.99, 0.76, 0.75]})\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        23\n",
      "           1       0.93      1.00      0.96        25\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.96      0.96      0.96        48\n",
      "weighted avg       0.96      0.96      0.96        48\n",
      "\n",
      "[[21  2]\n",
      " [ 0 25]]\n",
      "0.041666666666666664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        23\n",
      "           1       0.74      0.68      0.71        25\n",
      "\n",
      "    accuracy                           0.71        48\n",
      "   macro avg       0.71      0.71      0.71        48\n",
      "weighted avg       0.71      0.71      0.71        48\n",
      "\n",
      "[[17  6]\n",
      " [ 8 17]]\n",
      "0.2916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.43      0.56        23\n",
      "           1       0.63      0.88      0.73        25\n",
      "\n",
      "    accuracy                           0.67        48\n",
      "   macro avg       0.70      0.66      0.64        48\n",
      "weighted avg       0.70      0.67      0.65        48\n",
      "\n",
      "[[10 13]\n",
      " [ 3 22]]\n",
      "0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  F1-score\n",
       "0  Random Forest Classifier      0.96\n",
       "1                       SVM      0.71\n",
       "2       Logistic Regression      0.73"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cluster Centroids: under sampling \n",
    "\n",
    "CC = ClusterCentroids(random_state=12)\n",
    "X_res, y_res = CC.fit_sample(X, y)\n",
    "xtrain_cc, xtest_cc, ytrain_cc, ytest_cc = train_test_split(X_res, y_res, test_size=0.2, random_state=12)\n",
    "\n",
    "# testing \n",
    "\n",
    "pipeline_cc = Pipeline([('CC', CC), ('rfc', RandomForestClassifier(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_cc.fit(xtrain_cc, ytrain_cc) # fitting  \n",
    "pred_cc = pipeline_cc.predict(xtest_cc) # predicting \n",
    "print(classification_report(ytest_cc, pred_cc)) # results\n",
    "print(confusion_matrix(ytest_cc,pred_cc))\n",
    "print(mean_absolute_error(ytest_cc, pred_cc))\n",
    "sns.countplot(pred_cc)\n",
    "\n",
    "# 2 \n",
    "pipeline_cc_svm = Pipeline([('CC', CC), ('svm', svm.SVC(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_cc_svm.fit(xtrain_cc, ytrain_cc) # fitting  \n",
    "pred_cc_svm = pipeline_cc_svm.predict(xtest_cc) # predicting \n",
    "print(classification_report(ytest_cc, pred_cc_svm)) # results\n",
    "print(confusion_matrix(ytest_cc,pred_cc_svm))\n",
    "print(mean_absolute_error(ytest_cc, pred_cc_svm))\n",
    "sns.countplot(pred_cc_svm)\n",
    "\n",
    "# 3 \n",
    "pipeline_cc_lr = Pipeline([('CC', CC), ('lr', LogisticRegression(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_cc_lr.fit(xtrain_cc, ytrain_cc) # fitting  \n",
    "pred_cc_lr = pipeline_cc_lr.predict(xtest_cc) # predicting \n",
    "print(classification_report(ytest_cc, pred_cc_lr)) # results\n",
    "print(confusion_matrix(ytest_cc,pred_cc_lr))\n",
    "print(mean_absolute_error(ytest_cc, pred_cc_lr))\n",
    "sns.countplot(pred_cc_lr)\n",
    "\n",
    "\n",
    "final_results_cc = pd.DataFrame({'Model' : ['Random Forest Classifier', 'SVM', 'Logistic Regression'], 'F1-score' : [0.96, 0.71, 0.73]})\n",
    "\n",
    "final_results_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we used a generative model, the variational autoencoder (VAE) in order to generate new synthetic data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Strains function: with this function we are going to create two others dataframes (one for training and one for testing)\n",
    "# considering only the data corresponded to Class=1 (presence of strain). Why? Because we are going to train a VAE \n",
    "# in oerder to obtain new data that follow the statistical distribution of the presence of strain (in order to increase this class). \n",
    "\n",
    "def strain(dftrain, dftest):\n",
    "    ''' 1. select only Class = 1 values '''\n",
    "    strain = dftrain[dftrain.Class==1].sample(frac=1)\n",
    "    ''' 2. drop class from the dataset '''\n",
    "    strain = strain.drop(['Class'], axis=1)\n",
    "    straintest = dftest[dftest.Class==1].sample(frac=1)\n",
    "    straintest = straintest.drop(['Class'], axis=1)\n",
    "    return strain, straintest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is taken from Tensorflow tutorial on VAEs. It's turned from a CNN to a simple neuralnet which is more appropriate for our case here.\n",
    "\n",
    "# almost the standard for activation these days\n",
    "relu = tf.nn.relu\n",
    "\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A VAE class inhereted from keras.Model\n",
    "\n",
    "    parameters:\n",
    "    ndim (int): number of dimensions of the input data\n",
    "    latent_dim (int): number of dimensions of the latent variable\n",
    "\n",
    "    attributes:\n",
    "    ndim (int): number of dimensions of the input\n",
    "    latent_dim (int): number of dimensions of the latent variable\n",
    "    inference_net (keras.Sequential): The inference model that takes an input of size=(None, ndim) and return a matrix of size=(None, latent_dim)\n",
    "    generative_net (keras.Sequential): The generative model that takes an input of size=(None, latent_dim) and return a matrix of size=(None, ndim)\n",
    "    \"\"\"\n",
    "    def __init__(self, ndim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim  \n",
    "        self.ndim = ndim        \n",
    "        self.inference_net = Sequential(\n",
    "            [\n",
    "                InputLayer(input_shape=(ndim,)),\n",
    "                Dense(100, activation=relu),\n",
    "                Dense(2 * latent_dim)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.generative_net = Sequential(\n",
    "            [\n",
    "                InputLayer(input_shape=(latent_dim,)),\n",
    "                Dense(100, activation=relu),\n",
    "                Dense(ndim)\n",
    "            ])\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, num_samples=100, eps=None):\n",
    "        \"\"\"\n",
    "        Given an input noise of size (num_samples, latent_dim), generate samples of size (num_samples, ndim)\n",
    "\n",
    "        parameters:\n",
    "        num_samples (int): number of samples\n",
    "        eps (numpy.ndarray): input noise. if specified, num_samples is ignored\n",
    "\n",
    "        returns:\n",
    "        numpy.ndarray: the decoded samples\n",
    "        \"\"\"\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(num_samples, self.latent_dim))\n",
    "        return self.decode(eps)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        \n",
    "        parameters:\n",
    "        x (numpy.ndarray): the input data with size (None, ndim)\n",
    "\n",
    "        returns:\n",
    "        numpy.ndarray: the mean of the latent variables\n",
    "        numpy.ndarray: the log variance of the latent variables\n",
    "        \"\"\"\n",
    "        mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterize the input for backpropagation\n",
    "\n",
    "        parameters:\n",
    "        mean (numpy.ndarray): the mean of the latent variables\n",
    "        logvar (numpy.ndarray): the log variance of the latent variables\n",
    "\n",
    "        returns:\n",
    "        numpy.ndarray: the noise samples from a normal distribution around mean with standard deviation exp(logvar / 2)\n",
    "        \"\"\"\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Given an input noise generates the decoded samples\n",
    "\n",
    "        parameters:\n",
    "        z (numpy.ndarray): the input noise (None, latent_dim)\n",
    "\n",
    "        returns:\n",
    "        numpy.ndarray: the decoded samples of size (None, ndim)\n",
    "        \"\"\"\n",
    "        return self.generative_net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for computing the KL term of Gaussian distribution\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(-0.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "                         axis=raxis)\n",
    "\n",
    "# a function to compute the loss of the VAE\n",
    "@tf.function\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    logvar = tf.clip_by_value(logvar, -88., 88.)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    xmean = model.decode(z)\n",
    "    logpx_z = -tf.reduce_sum((x - xmean) ** 2, axis=1)  # ad-hoc l2 loss that is pretty close to log-prob of a gaussian distribution withtout taking into account the variance\n",
    "    logpz = log_normal_pdf(z, 0.0, 0.0)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "# A function that given the model computes the loss, the gradients and apply the parameter update\n",
    "@tf.function\n",
    "def compute_apply_gradients(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(xtrain, xtest, model=None, load=False, filepath=None):\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "    epochs = 2000\n",
    "    latent_dim = 6 # number of our columns\n",
    "    num_train, ndim = xtrain.shape\n",
    "    num_test, _ = xtest.shape\n",
    "    if model is None:\n",
    "        model = VAE(ndim, latent_dim)\n",
    "    if load and filepath is not None:\n",
    "        model.load_weights(filepath=filepath)\n",
    "        return model\n",
    "    else:\n",
    "        batch_size = 32\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(xtrain.values.astype(np.float32)).shuffle(num_train).batch(\n",
    "            batch_size)\n",
    "\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(xtest.values.astype(np.float32)).shuffle(num_test).batch(num_test)\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            start_time = time.time()\n",
    "            for train_x in train_dataset:\n",
    "                compute_apply_gradients(model, train_x, optimizer)\n",
    "            end_time = time.time()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                loss = tf.keras.metrics.Mean()\n",
    "                for test_x in test_dataset:\n",
    "                    loss(compute_loss(model, test_x))\n",
    "                elbo = -loss.result()\n",
    "                print('Epoch: {}, Test set psudo-ELBO: {}, '\n",
    "                      'time elapse for current epoch {}'.format(epoch, elbo, end_time - start_time))\n",
    "                model.save_weights('saved_models/model_%d_at_%d' % (latent_dim, epoch))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to increase the minority class: \n",
    "def increasing(data, model):\n",
    "    np.random.seed(12)\n",
    "    ''' num_samples = number of values of majority class (0) '''\n",
    "    num_samples = num_samples = data['Class'].value_counts()[0] - data['Class'].value_counts()[1]  # values of class == 1 \n",
    "    samples = model.sample(num_samples=num_samples).numpy()\n",
    "    ''' creating new dataframe with sampled values '''\n",
    "    dfnew = pd.DataFrame(samples, columns=data.columns.drop('Class'))\n",
    "    dfnew['Class'] = np.ones(len(samples), dtype=np.int)\n",
    "    # dfnew = pd.concat((data, dfnew), ignore_index=True).sample(frac=1)\n",
    "    return dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Test set psudo-ELBO: -7.592565059661865, time elapse for current epoch 0.03992486000061035\n",
      "Epoch: 200, Test set psudo-ELBO: -7.1905951499938965, time elapse for current epoch 0.009881019592285156\n",
      "Epoch: 300, Test set psudo-ELBO: -6.337263107299805, time elapse for current epoch 0.016149044036865234\n",
      "Epoch: 400, Test set psudo-ELBO: -6.406667709350586, time elapse for current epoch 0.011677980422973633\n",
      "Epoch: 500, Test set psudo-ELBO: -5.939108371734619, time elapse for current epoch 0.019390106201171875\n",
      "Epoch: 600, Test set psudo-ELBO: -5.648345947265625, time elapse for current epoch 0.01129007339477539\n",
      "Epoch: 700, Test set psudo-ELBO: -5.7330803871154785, time elapse for current epoch 0.009420633316040039\n",
      "Epoch: 800, Test set psudo-ELBO: -5.573282718658447, time elapse for current epoch 0.01353907585144043\n",
      "Epoch: 900, Test set psudo-ELBO: -5.617308139801025, time elapse for current epoch 0.009009838104248047\n",
      "Epoch: 1000, Test set psudo-ELBO: -5.54238748550415, time elapse for current epoch 0.011245965957641602\n",
      "Epoch: 1100, Test set psudo-ELBO: -5.808038711547852, time elapse for current epoch 0.008269071578979492\n",
      "Epoch: 1200, Test set psudo-ELBO: -5.489194393157959, time elapse for current epoch 0.0169680118560791\n",
      "Epoch: 1300, Test set psudo-ELBO: -5.652456760406494, time elapse for current epoch 0.010503292083740234\n",
      "Epoch: 1400, Test set psudo-ELBO: -5.315123081207275, time elapse for current epoch 0.009611129760742188\n",
      "Epoch: 1500, Test set psudo-ELBO: -5.3398308753967285, time elapse for current epoch 0.012181997299194336\n",
      "Epoch: 1600, Test set psudo-ELBO: -5.026716709136963, time elapse for current epoch 0.017436981201171875\n",
      "Epoch: 1700, Test set psudo-ELBO: -5.067348480224609, time elapse for current epoch 0.011924028396606445\n",
      "Epoch: 1800, Test set psudo-ELBO: -5.073044776916504, time elapse for current epoch 0.010973215103149414\n",
      "Epoch: 1900, Test set psudo-ELBO: -5.139735221862793, time elapse for current epoch 0.01110386848449707\n",
      "Epoch: 2000, Test set psudo-ELBO: -5.251914978027344, time elapse for current epoch 0.02390313148498535\n"
     ]
    }
   ],
   "source": [
    "# Use the function to obtain 2 dataframes: \n",
    "dftrain, dftest = prepare_data(data)\n",
    "# get the strains'presence distribution \n",
    "strain, straintest = strain(dftrain, dftest)\n",
    "# get the traied VAE model\n",
    "model = train(strain, straintest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the data using the VAE model\n",
    "data_increased = increasing(dftrain, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality control "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first quality control we did has been checking the mean of two variables of interest: Ratio_1kbp_bins_covered and Reads Mapped. We selected these two variables because we previously saw that the coverage has a greate influence on the number of predicted strains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016082</td>\n",
       "      <td>-0.06098</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>-0.060841</td>\n",
       "      <td>-0.005691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405132</td>\n",
       "      <td>1.53619</td>\n",
       "      <td>-0.416753</td>\n",
       "      <td>-0.077574</td>\n",
       "      <td>1.532687</td>\n",
       "      <td>0.143355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genome_length  Ratio_1kbp_bins_covered  \\\n",
       "Class                                           \n",
       "0          -0.016082                 -0.06098   \n",
       "1           0.405132                  1.53619   \n",
       "\n",
       "       Ratio_GC-content_uncovered_bins  Ratio_N-content_uncovered_bins  \\\n",
       "Class                                                                    \n",
       "0                             0.016543                        0.003079   \n",
       "1                            -0.416753                       -0.077574   \n",
       "\n",
       "       Reads_mapped  Total_reads  \n",
       "Class                             \n",
       "0         -0.060841    -0.005691  \n",
       "1          1.532687     0.143355  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class').mean() #1.53619 and 1.532687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.263434</td>\n",
       "      <td>1.542465</td>\n",
       "      <td>-0.467348</td>\n",
       "      <td>-0.134053</td>\n",
       "      <td>1.498506</td>\n",
       "      <td>0.17623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genome_length  Ratio_1kbp_bins_covered  \\\n",
       "Class                                           \n",
       "1           0.263434                 1.542465   \n",
       "\n",
       "       Ratio_GC-content_uncovered_bins  Ratio_N-content_uncovered_bins  \\\n",
       "Class                                                                    \n",
       "1                            -0.467348                       -0.134053   \n",
       "\n",
       "       Reads_mapped  Total_reads  \n",
       "Class                             \n",
       "1          1.498506      0.17623  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_increased.groupby('Class').mean() #1.586048 and 1.500616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the new and the original data: we have to create the final dataset\n",
    "merged_data = pd.concat((data, data_increased), ignore_index=True) # .sample(frac=1)\n",
    "\n",
    "# Shuffle data \n",
    "from sklearn.utils import shuffle\n",
    "merged_data = shuffle(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>-0.078239</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.546468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>-0.521593</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>-1.425987</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.115585</td>\n",
       "      <td>-0.619181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>-0.023991</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.718160</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>1.944562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>0.150795</td>\n",
       "      <td>0.287865</td>\n",
       "      <td>-0.821955</td>\n",
       "      <td>-0.214715</td>\n",
       "      <td>-0.134635</td>\n",
       "      <td>-0.679028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4361</th>\n",
       "      <td>-0.071812</td>\n",
       "      <td>3.179194</td>\n",
       "      <td>-0.470857</td>\n",
       "      <td>-0.101062</td>\n",
       "      <td>7.280993</td>\n",
       "      <td>1.419568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Genome_length  Ratio_1kbp_bins_covered  Ratio_GC-content_uncovered_bins  \\\n",
       "1979      -0.078239                -0.220521                         0.873623   \n",
       "2127      -0.521593                 0.433013                        -1.425987   \n",
       "920       -0.023991                -0.220521                         0.718160   \n",
       "4631       0.150795                 0.287865                        -0.821955   \n",
       "4361      -0.071812                 3.179194                        -0.470857   \n",
       "\n",
       "      Ratio_N-content_uncovered_bins  Reads_mapped  Total_reads  Class  \n",
       "1979                       -0.168520     -0.117818    -0.546468      0  \n",
       "2127                       -0.168520     -0.115585    -0.619181      0  \n",
       "920                        -0.168520     -0.117818     1.944562      0  \n",
       "4631                       -0.214715     -0.134635    -0.679028      1  \n",
       "4361                       -0.101062      7.280993     1.419568      1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (329245332)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bar plot with ggplot of SMOTE distribution \n",
    "from plotnine import *\n",
    "p = ggplot(merged_data) + geom_bar(aes(x='Class'), fill = \"yellow\", colour = \"blue\")\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we obtained well - balanced data, we could test again the machine learning models of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the models on the new data \n",
    "# Defining X and Y \n",
    "X_final = merged_data.drop('Class', axis=1) # data increased with VAE \n",
    "y_final = merged_data['Class']\n",
    "\n",
    "# Split the data \n",
    "xtrain_f, xtest_f, ytrain_f, ytest_f = train_test_split(X_final, y_final, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       583\n",
      "           1       0.99      0.99      0.99       510\n",
      "\n",
      "    accuracy                           0.99      1093\n",
      "   macro avg       0.99      0.99      0.99      1093\n",
      "weighted avg       0.99      0.99      0.99      1093\n",
      "\n",
      "[[577   6]\n",
      " [  3 507]]\n",
      "Accuracy :  0.9917657822506862\n",
      "Sensitivity :  0.9897084048027445\n",
      "Specificity :  0.9941176470588236\n"
     ]
    }
   ],
   "source": [
    "# Model 1 \n",
    "rfc = RandomForestClassifier(n_estimators = 200, random_state = 12)\n",
    "rfc.fit(xtrain_f, ytrain_f)\n",
    "pred_rfc = rfc.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, pred_rfc))\n",
    "print(confusion_matrix(ytest_f, pred_rfc))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm1 = (confusion_matrix(ytest_f, pred_rfc)) \n",
    "total1 = sum(sum(cm1))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       583\n",
      "           1       0.93      0.82      0.87       510\n",
      "\n",
      "    accuracy                           0.89      1093\n",
      "   macro avg       0.89      0.88      0.89      1093\n",
      "weighted avg       0.89      0.89      0.89      1093\n",
      "\n",
      "[[551  32]\n",
      " [ 91 419]]\n",
      "Accuracy :  0.8874656907593779\n",
      "Sensitivity :  0.9451114922813036\n",
      "Specificity :  0.8215686274509804\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "SVM = svm.SVC(random_state = 12)\n",
    "SVM.fit(xtrain_f, ytrain_f)\n",
    "pred_SVM = SVM.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, pred_SVM)) \n",
    "print(confusion_matrix(ytest_f, pred_SVM)) \n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm2 = (confusion_matrix(ytest_f, pred_SVM)) \n",
    "total2=sum(sum(cm2))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy2=(cm2[0,0]+cm2[1,1])/total2\n",
    "print ('Accuracy : ', accuracy2)\n",
    "\n",
    "sensitivity2 = cm2[0,0]/(cm2[0,0]+cm2[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "\n",
    "specificity2 = cm2[1,1]/(cm2[1,0]+cm2[1,1]) # TN / (TN + FP)\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85       583\n",
      "           1       0.89      0.73      0.80       510\n",
      "\n",
      "    accuracy                           0.83      1093\n",
      "   macro avg       0.84      0.83      0.83      1093\n",
      "weighted avg       0.84      0.83      0.83      1093\n",
      "\n",
      "[[536  47]\n",
      " [137 373]]\n",
      "Accuracy :  0.8316559926806953\n",
      "Sensitivity :  0.9193825042881647\n",
      "Specificity :  0.7313725490196078\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "logreg = LogisticRegression(solver='lbfgs', random_state = 12)\n",
    "logreg.fit(xtrain_f, ytrain_f)\n",
    "pred_logreg = logreg.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, pred_logreg)) \n",
    "print(confusion_matrix(ytest_f, pred_logreg)) \n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm3 = (confusion_matrix(ytest_f, pred_logreg)) \n",
    "total3=sum(sum(cm3))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy3=(cm3[0,0]+cm3[1,1])/total3\n",
    "print ('Accuracy : ', accuracy3)\n",
    "\n",
    "sensitivity3 = cm3[0,0]/(cm3[0,0]+cm3[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity3 )\n",
    "\n",
    "specificity3 = cm3[1,1]/(cm3[1,0]+cm3[1,1]) # TN / (TN + FP)\n",
    "print('Specificity : ', specificity3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       583\n",
      "           1       0.98      0.99      0.99       510\n",
      "\n",
      "    accuracy                           0.99      1093\n",
      "   macro avg       0.99      0.99      0.99      1093\n",
      "weighted avg       0.99      0.99      0.99      1093\n",
      "\n",
      "[[575   8]\n",
      " [  7 503]]\n",
      "0.013723696248856358\n",
      "Accuracy :  0.9862763037511436\n",
      "Sensitivity :  0.9862778730703259\n",
      "Specificity :  0.9862745098039216\n"
     ]
    }
   ],
   "source": [
    "# Model 4 \n",
    "gbc = GradientBoostingClassifier(random_state=12)\n",
    "gbc.fit(xtrain_f,ytrain_f)\n",
    "predict_gbc = gbc.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, predict_gbc))\n",
    "print(confusion_matrix(ytest_f, predict_gbc))\n",
    "\n",
    "# error between data generated and original data \n",
    "print(mean_absolute_error(predict_gbc, ytest_f))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm1 = (confusion_matrix(ytest_f, predict_gbc)) \n",
    "total1 = sum(sum(cm1))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       583\n",
      "           1       0.98      0.99      0.99       510\n",
      "\n",
      "    accuracy                           0.99      1093\n",
      "   macro avg       0.99      0.99      0.99      1093\n",
      "weighted avg       0.99      0.99      0.99      1093\n",
      "\n",
      "[[575   8]\n",
      " [  5 505]]\n",
      "0.011893870082342177\n",
      "Accuracy :  0.9881061299176578\n",
      "Sensitivity :  0.9862778730703259\n",
      "Specificity :  0.9901960784313726\n"
     ]
    }
   ],
   "source": [
    "# Model 5 \n",
    "xgb_boost = xgb.XGBClassifier(random_state=12)\n",
    "xgb_boost.fit(xtrain_f, ytrain_f)\n",
    "predict_xgb_boost = xgb_boost.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, predict_xgb_boost))\n",
    "print(confusion_matrix(ytest_f, predict_xgb_boost))\n",
    "\n",
    "# error between data generated and original data \n",
    "print(mean_absolute_error(predict_xgb_boost, ytest_f))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm2 = (confusion_matrix(ytest_f, predict_xgb_boost)) \n",
    "total2 = sum(sum(cm2))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy2 = (cm2[0,0]+cm2[1,1])/total2\n",
    "print ('Accuracy : ', accuracy2)\n",
    "\n",
    "sensitivity2 = cm2[0,0]/(cm2[0,0]+cm2[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "\n",
    "specificity2 = cm2[1,1]/(cm2[1,0]+cm2[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       583\n",
      "           1       0.97      0.98      0.98       510\n",
      "\n",
      "    accuracy                           0.98      1093\n",
      "   macro avg       0.98      0.98      0.98      1093\n",
      "weighted avg       0.98      0.98      0.98      1093\n",
      "\n",
      "[[570  13]\n",
      " [  8 502]]\n",
      "0.0192131747483989\n",
      "Accuracy :  0.9807868252516011\n",
      "Sensitivity :  0.9777015437392796\n",
      "Specificity :  0.984313725490196\n"
     ]
    }
   ],
   "source": [
    "# Model 6\n",
    "ada = AdaBoostClassifier(random_state=12)\n",
    "ada.fit(xtrain_f,ytrain_f)\n",
    "predict_ada = ada.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, predict_ada))\n",
    "print(confusion_matrix(ytest_f, predict_ada))\n",
    "\n",
    "# error between data generated and original data \n",
    "print(mean_absolute_error(predict_ada, ytest_f))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm = (confusion_matrix(ytest_f, predict_ada)) \n",
    "total = sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy = (cm[0,0]+cm[1,1])/total\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "specificity = cm[1,1]/(cm[1,0]+cm[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to obtain the best hyperparameters for each model we are going to apply the GridSearch - Hyperparameters tuning. Moreover, we compare the models to each other to check which is the best (higher F1-score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'SVM' : {\n",
    "        'Model': svm.SVC(random_state = 1),\n",
    "        'Params': {\n",
    "            'C' : [1,10,100,1000],\n",
    "            'gamma' : [1e-3, 1e-4], \n",
    "        }\n",
    "    },\n",
    "    'Random_forest' : {\n",
    "        'Model': RandomForestClassifier(random_state = 1),\n",
    "        'Params': {\n",
    "            'n_estimators' : [100,500,800],\n",
    "            'oob_score' : [False, True]\n",
    "        }\n",
    "    },\n",
    "    'Logistic_regression' : {\n",
    "        'Model': LogisticRegression(random_state = 1),\n",
    "        'Params': {\n",
    "        'C' : [1,10,100,1000],\n",
    "            'penalty' : ['l1', 'l2'],\n",
    "            'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }\n",
    "},\n",
    "    'Gradient_Boosting' : {\n",
    "        'Model' : GradientBoostingClassifier(random_state = 1),\n",
    "        'Params' : {\n",
    "            'ccp_alpha' : [0.0,0.5,0.7], \n",
    "            'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], \n",
    "            'n_estimators':[100,200,400,600,800]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'XGB_Boosting' : {\n",
    "        'Model' : xgb.XGBClassifier(random_state = 1),\n",
    "        'Params' : {\n",
    "            'base_score' : [0.0,0.5,0.7], \n",
    "            'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], \n",
    "            'n_estimators':[100,200,400,600,800]  \n",
    "        }\n",
    "    }, \n",
    "    \n",
    "    'Ada_Boosting' : {\n",
    "        'Model' : AdaBoostClassifier(random_state = 1),\n",
    "        'Params' : {\n",
    "            'algorithm' : ['SAMME', 'SAMME.R'], \n",
    "            'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], \n",
    "            'n_estimators':[100,200,400,600,800]  \n",
    "        }\n",
    "    } \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "np.random.seed(12)\n",
    "for model_name, mp in model_params.items():\n",
    "    final_model = GridSearchCV(mp['Model'], mp['Params'], cv=5, return_train_score=False, scoring='f1_micro')\n",
    "    final_model.fit(X_final,y_final)\n",
    "    scores.append({\n",
    "        'Model': model_name,\n",
    "        'Best score' : final_model.best_score_,\n",
    "        'Best params': final_model.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params_table = pd.DataFrame(scores,columns=['Model', 'Best score', 'Best params']).sort_values(by=['Best score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best score</th>\n",
       "      <th>Best params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB_Boosting</td>\n",
       "      <td>0.991034</td>\n",
       "      <td>{'base_score': 0.5, 'learning_rate': 0.1, 'n_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.990302</td>\n",
       "      <td>{'n_estimators': 500, 'oob_score': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient_Boosting</td>\n",
       "      <td>0.988106</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'learning_rate': 0.2, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada_Boosting</td>\n",
       "      <td>0.983898</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'learning_rate': 0.3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.865508</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic_regression</td>\n",
       "      <td>0.835316</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Best score  \\\n",
       "4         XGB_Boosting    0.991034   \n",
       "1        Random_forest    0.990302   \n",
       "3    Gradient_Boosting    0.988106   \n",
       "5         Ada_Boosting    0.983898   \n",
       "0                  SVM    0.865508   \n",
       "2  Logistic_regression    0.835316   \n",
       "\n",
       "                                         Best params  \n",
       "4  {'base_score': 0.5, 'learning_rate': 0.1, 'n_e...  \n",
       "1          {'n_estimators': 500, 'oob_score': False}  \n",
       "3  {'ccp_alpha': 0.0, 'learning_rate': 0.2, 'n_es...  \n",
       "5  {'algorithm': 'SAMME.R', 'learning_rate': 0.3,...  \n",
       "0                        {'C': 1000, 'gamma': 0.001}  \n",
       "2   {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_params_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5, 'learning_rate': 0.1, 'n_estimators': 600}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_params_table.iloc[0,2] # to check the best parameters of the XGB_Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       583\n",
      "           1       0.99      0.99      0.99       510\n",
      "\n",
      "    accuracy                           0.99      1093\n",
      "   macro avg       0.99      0.99      0.99      1093\n",
      "weighted avg       0.99      0.99      0.99      1093\n",
      "\n",
      "[[577   6]\n",
      " [  4 506]]\n",
      "Accuracy :  0.9908508691674291\n",
      "Sensitivity :  0.9897084048027445\n",
      "Specificity :  0.9921568627450981\n"
     ]
    }
   ],
   "source": [
    "final_model = xgb.XGBClassifier(base_score = 0.5, learning_rate = 0.1, n_estimators = 600, random_state=12)\n",
    "final_model.fit(xtrain_f, ytrain_f)\n",
    "final_predict = final_model.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, final_predict))\n",
    "print(confusion_matrix(ytest_f, final_predict))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm2 = (confusion_matrix(ytest_f, final_predict)) \n",
    "total2 = sum(sum(cm2))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy2 = (cm2[0,0]+cm2[1,1])/total2\n",
    "print ('Accuracy : ', accuracy2)\n",
    "\n",
    "sensitivity2 = cm2[0,0]/(cm2[0,0]+cm2[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "\n",
    "specificity2 = cm2[1,1]/(cm2[1,0]+cm2[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model\n",
      "[[577   6]\n",
      " [  4 506]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "titles_options = [('Final Model')]\n",
    "for title in titles_options:\n",
    "    disp = plot_confusion_matrix(final_model, xtest_f, ytest_f)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x139386be0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(final_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pickle object of the final model : \n",
    "import pickle    \n",
    "\n",
    "#save the model\n",
    "pickle.dump(final_model, open('final_model.sav', 'wb'))\n",
    "# save the scaler\n",
    "pickle.dump(sc, open('scaler.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
