{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling with VAE - from tensorflow / tabular data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, average_precision_score, precision_recall_curve\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data and change columns names\n",
    "data = pd.read_excel('final.xlsm', header=None)\n",
    "data.columns =['Strain_ID', 'Genome_length', 'Ratio_1kbp_bins_covered', 'Ratio_GC-content_uncovered_bins', 'Ratio_N-content_uncovered_bins', 'Reads_mapped', 'Total_reads', 'Class']\n",
    "# 2. Drop the Strain_ID column\n",
    "data = data.drop(['Strain_ID'], axis=1)\n",
    "# 3. Normalize columns except Class col\n",
    "sc = StandardScaler()\n",
    "data[['Genome_length', 'Ratio_1kbp_bins_covered', 'Ratio_GC-content_uncovered_bins', 'Ratio_N-content_uncovered_bins', 'Reads_mapped', 'Total_reads']] = sc.fit_transform(data[['Genome_length', 'Ratio_1kbp_bins_covered', 'Ratio_GC-content_uncovered_bins', 'Ratio_N-content_uncovered_bins', 'Reads_mapped', 'Total_reads']])\n",
    "\n",
    "\n",
    "# 1. Prepare data: \n",
    "def prepare_data(data,random_state=12):\n",
    "    X = data.drop('Class', axis=1)\n",
    "    y = data['Class']\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    dftrain = [xtrain, ytrain]\n",
    "    dftest = [xtest, ytest]\n",
    "    return pd.concat(dftrain, axis=1), pd.concat(dftest, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.228558</td>\n",
       "      <td>-0.219520</td>\n",
       "      <td>1.078705</td>\n",
       "      <td>-0.168407</td>\n",
       "      <td>-0.117813</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.039962</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.485007</td>\n",
       "      <td>-0.154483</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075952</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.696596</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.245584</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.590566</td>\n",
       "      <td>-0.168305</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.608627</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>0.683660</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>-0.420667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genome_length  Ratio_1kbp_bins_covered  Ratio_GC-content_uncovered_bins  \\\n",
       "0       0.228558                -0.219520                         1.078705   \n",
       "1       4.039962                -0.220521                         0.485007   \n",
       "2       0.075952                -0.220521                         0.696596   \n",
       "3       2.245584                -0.220521                         0.590566   \n",
       "4       0.608627                -0.220521                         0.683660   \n",
       "\n",
       "   Ratio_N-content_uncovered_bins  Reads_mapped  Total_reads  Class  \n",
       "0                       -0.168407     -0.117813    -0.420667      0  \n",
       "1                       -0.154483     -0.117818    -0.420667      0  \n",
       "2                       -0.168520     -0.117818    -0.420667      0  \n",
       "3                       -0.168305     -0.117818    -0.420667      0  \n",
       "4                       -0.168520     -0.117818    -0.420667      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to obtain 2 dataframes: \n",
    "dftrain, dftest = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118542a60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Class']) # initial distribution of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Strains function: \n",
    "def strain(dftrain, dftest):\n",
    "    ''' 1. select only Class = 1 values '''\n",
    "    strain = dftrain[dftrain.Class==1].sample(frac=1)\n",
    "    ''' 2. drop class from the dataset '''\n",
    "    strain = strain.drop(['Class'], axis=1)\n",
    "    straintest = dftest[dftest.Class==1].sample(frac=1)\n",
    "    straintest = straintest.drop(['Class'], axis=1)\n",
    "    return strain, straintest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Reshape\n",
    "from tensorflow.keras import Sequential\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is taken from Tensorflow tutorial on VAEs. It's turned from a CNN to a simple neuralnet which is more appropriate for our case here.\n",
    "\n",
    "# almost the standard for activation these days\n",
    "relu = tf.nn.relu\n",
    "\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A VAE class inhereted from keras.Model\n",
    "\n",
    "    parameters:\n",
    "    ndim (int): number of dimensions of the input data\n",
    "    latent_dim (int): number of dimensions of the latent variable\n",
    "\n",
    "    attributes:\n",
    "    ndim (int): number of dimensions of the input\n",
    "    latent_dim (int): number of dimensions of the latent variable\n",
    "    inference_net (keras.Sequential): The inference model that takes an input of size=(None, ndim) and return a matrix of size=(None, latent_dim)\n",
    "    generative_net (keras.Sequential): The generative model that takes an input of size=(None, latent_dim) and return a matrix of size=(None, ndim)\n",
    "    \"\"\"\n",
    "    def __init__(self, ndim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim  \n",
    "        self.ndim = ndim        \n",
    "        self.inference_net = Sequential(\n",
    "            [\n",
    "                InputLayer(input_shape=(ndim,)),\n",
    "                Dense(100, activation=relu),\n",
    "                Dense(2 * latent_dim)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.generative_net = Sequential(\n",
    "            [\n",
    "                InputLayer(input_shape=(latent_dim,)),\n",
    "                Dense(100, activation=relu),\n",
    "                Dense(ndim)\n",
    "            ])\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, num_samples=100, eps=None):\n",
    "        \"\"\"\n",
    "        Given an input noise of size (num_samples, latent_dim), generate samples of size (num_samples, ndim)\n",
    "\n",
    "        parameters:\n",
    "        num_samples (int): number of samples\n",
    "        eps (numpy.ndarray): input noise. if specified, num_samples is ignored\n",
    "\n",
    "        returns:\n",
    "        numpy.ndarray: the decoded samples\n",
    "        \"\"\"\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(num_samples, self.latent_dim))\n",
    "        return self.decode(eps)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        \n",
    "        parameters:\n",
    "        x (numpy.ndarray): the input data with size (None, ndim)\n",
    "\n",
    "        returns:\n",
    "        numpy.ndarray: the mean of the latent variables\n",
    "        numpy.ndarray: the log variance of the latent variables\n",
    "        \"\"\"\n",
    "        mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterize the input for backpropagation\n",
    "\n",
    "        parameters:\n",
    "        mean (numpy.ndarray): the mean of the latent variables\n",
    "        logvar (numpy.ndarray): the log variance of the latent variables\n",
    "\n",
    "        returns:\n",
    "        numpy.ndarray: the noise samples from a normal distribution around mean with standard deviation exp(logvar / 2)\n",
    "        \"\"\"\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Given an input noise generates the decoded samples\n",
    "\n",
    "        parameters:\n",
    "        z (numpy.ndarray): the input noise (None, latent_dim)\n",
    "\n",
    "        returns:\n",
    "        numpy.ndarray: the decoded samples of size (None, ndim)\n",
    "        \"\"\"\n",
    "        return self.generative_net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for computing the KL term of Gaussian distribution\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(-0.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "                         axis=raxis)\n",
    "\n",
    "# a function to compute the loss of the VAE\n",
    "@tf.function\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    logvar = tf.clip_by_value(logvar, -88., 88.)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    xmean = model.decode(z)\n",
    "    logpx_z = -tf.reduce_sum((x - xmean) ** 2, axis=1)  # ad-hoc l2 loss that is pretty close to log-prob of a gaussian distribution withtout taking into account the variance\n",
    "    logpz = log_normal_pdf(z, 0.0, 0.0)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "# A function that given the model computes the loss, the gradients and apply the parameter update\n",
    "@tf.function\n",
    "def compute_apply_gradients(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(xtrain, xtest, model=None, load=False, filepath=None):\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "    epochs = 2000\n",
    "    latent_dim = 6 # number of our columns\n",
    "    num_train, ndim = xtrain.shape\n",
    "    num_test, _ = xtest.shape\n",
    "    if model is None:\n",
    "        model = VAE(ndim, latent_dim)\n",
    "    if load and filepath is not None:\n",
    "        model.load_weights(filepath=filepath)\n",
    "        return model\n",
    "    else:\n",
    "        batch_size = 32\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(xtrain.values.astype(np.float32)).shuffle(num_train).batch(\n",
    "            batch_size)\n",
    "\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(xtest.values.astype(np.float32)).shuffle(num_test).batch(num_test)\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            start_time = time.time()\n",
    "            for train_x in train_dataset:\n",
    "                compute_apply_gradients(model, train_x, optimizer)\n",
    "            end_time = time.time()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                loss = tf.keras.metrics.Mean()\n",
    "                for test_x in test_dataset:\n",
    "                    loss(compute_loss(model, test_x))\n",
    "                elbo = -loss.result()\n",
    "                print('Epoch: {}, Test set psudo-ELBO: {}, '\n",
    "                      'time elapse for current epoch {}'.format(epoch, elbo, end_time - start_time))\n",
    "                model.save_weights('saved_models/model_%d_at_%d' % (latent_dim, epoch))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to increase the 1 of Class \n",
    "def increasing(data, model):\n",
    "    np.random.seed(12)\n",
    "    ''' num_samples = number of values of majority class (0) '''\n",
    "    num_samples = num_samples = data['Class'].value_counts()[0] - data['Class'].value_counts()[1]  # values of class == 1 \n",
    "    samples = model.sample(num_samples=num_samples).numpy()\n",
    "    ''' creating new dataframe with sampled values '''\n",
    "    dfnew = pd.DataFrame(samples, columns=data.columns.drop('Class'))\n",
    "    dfnew['Class'] = np.ones(len(samples), dtype=np.int)\n",
    "    # dfnew = pd.concat((data, dfnew), ignore_index=True).sample(frac=1)\n",
    "    return dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Test set psudo-ELBO: -7.6699910163879395, time elapse for current epoch 0.007887125015258789\n",
      "Epoch: 200, Test set psudo-ELBO: -6.738650798797607, time elapse for current epoch 0.00783395767211914\n",
      "Epoch: 300, Test set psudo-ELBO: -6.742164611816406, time elapse for current epoch 0.008627891540527344\n",
      "Epoch: 400, Test set psudo-ELBO: -6.4114909172058105, time elapse for current epoch 0.008809089660644531\n",
      "Epoch: 500, Test set psudo-ELBO: -6.138607025146484, time elapse for current epoch 0.009299993515014648\n",
      "Epoch: 600, Test set psudo-ELBO: -5.405642032623291, time elapse for current epoch 0.012384891510009766\n",
      "Epoch: 700, Test set psudo-ELBO: -6.496571063995361, time elapse for current epoch 0.00801992416381836\n",
      "Epoch: 800, Test set psudo-ELBO: -6.015525817871094, time elapse for current epoch 0.009629964828491211\n",
      "Epoch: 900, Test set psudo-ELBO: -5.634790897369385, time elapse for current epoch 0.011983871459960938\n",
      "Epoch: 1000, Test set psudo-ELBO: -5.379653453826904, time elapse for current epoch 0.008874893188476562\n",
      "Epoch: 1100, Test set psudo-ELBO: -5.634941101074219, time elapse for current epoch 0.014567136764526367\n",
      "Epoch: 1200, Test set psudo-ELBO: -6.398397922515869, time elapse for current epoch 0.009435892105102539\n",
      "Epoch: 1300, Test set psudo-ELBO: -5.558465480804443, time elapse for current epoch 0.011117935180664062\n",
      "Epoch: 1400, Test set psudo-ELBO: -5.301626205444336, time elapse for current epoch 0.01306915283203125\n",
      "Epoch: 1500, Test set psudo-ELBO: -5.603618621826172, time elapse for current epoch 0.008088111877441406\n",
      "Epoch: 1600, Test set psudo-ELBO: -5.351969242095947, time elapse for current epoch 0.011706113815307617\n",
      "Epoch: 1700, Test set psudo-ELBO: -5.1601338386535645, time elapse for current epoch 0.007818937301635742\n",
      "Epoch: 1800, Test set psudo-ELBO: -4.770335674285889, time elapse for current epoch 0.011301040649414062\n",
      "Epoch: 1900, Test set psudo-ELBO: -5.038590908050537, time elapse for current epoch 0.008309125900268555\n",
      "Epoch: 2000, Test set psudo-ELBO: -5.103214263916016, time elapse for current epoch 0.014331817626953125\n"
     ]
    }
   ],
   "source": [
    "# Use the function to obtain 2 dataframes: \n",
    "dftrain, dftest = prepare_data(data)\n",
    "# get the strains'presence distribution \n",
    "strain, straintest = strain(dftrain, dftest)\n",
    "# get the traied VAE model\n",
    "model = train(strain, straintest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the data using the VAE model\n",
    "data_increased = increasing(dftrain, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016082</td>\n",
       "      <td>-0.06098</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>-0.060841</td>\n",
       "      <td>-0.005691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405132</td>\n",
       "      <td>1.53619</td>\n",
       "      <td>-0.416753</td>\n",
       "      <td>-0.077574</td>\n",
       "      <td>1.532687</td>\n",
       "      <td>0.143355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genome_length  Ratio_1kbp_bins_covered  \\\n",
       "Class                                           \n",
       "0          -0.016082                 -0.06098   \n",
       "1           0.405132                  1.53619   \n",
       "\n",
       "       Ratio_GC-content_uncovered_bins  Ratio_N-content_uncovered_bins  \\\n",
       "Class                                                                    \n",
       "0                             0.016543                        0.003079   \n",
       "1                            -0.416753                       -0.077574   \n",
       "\n",
       "       Reads_mapped  Total_reads  \n",
       "Class                             \n",
       "0         -0.060841    -0.005691  \n",
       "1          1.532687     0.143355  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class').mean() #1.53619 and 1.532687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.234057</td>\n",
       "      <td>1.60099</td>\n",
       "      <td>-0.408038</td>\n",
       "      <td>-0.135459</td>\n",
       "      <td>1.427738</td>\n",
       "      <td>0.182888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genome_length  Ratio_1kbp_bins_covered  \\\n",
       "Class                                           \n",
       "1           0.234057                  1.60099   \n",
       "\n",
       "       Ratio_GC-content_uncovered_bins  Ratio_N-content_uncovered_bins  \\\n",
       "Class                                                                    \n",
       "1                            -0.408038                       -0.135459   \n",
       "\n",
       "       Reads_mapped  Total_reads  \n",
       "Class                             \n",
       "1          1.427738     0.182888  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_increased.groupby('Class').mean() #1.586048 and 1.500616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2322, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_increased.shape # 2322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_increased.to_excel('data_increased.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_interpolation(data, model):\n",
    "    num_samples = data['Class'].value_counts()[0] - data['Class'].value_counts()[1]\n",
    "    X = data[data['Class'] == 1].drop(['Class'], axis=1)\n",
    "    z, _ = model.encode(X.values.astype(np.float32))\n",
    "    z1 = pd.DataFrame(z).sample(frac=num_samples / len(z), replace=True)\n",
    "    z2 = z1.sample(frac=1)\n",
    "    r = np.random.rand(*z1.shape)\n",
    "    z = r * z1.values + (1 - r) * z2.values\n",
    "    samples = model.decode(z.astype(np.float32)).numpy()\n",
    "    dfnew = pd.DataFrame(samples, columns=data.columns.drop('Class'))\n",
    "    dfnew['Class'] = np.ones(len(samples), dtype=np.int)\n",
    "    # dfnew = pd.concat((data, dfnew), ignore_index=True).sample(frac=1)\n",
    "    return dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_interpolated = augment_data_interpolation(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21907</td>\n",
       "      <td>1.516348</td>\n",
       "      <td>-0.481275</td>\n",
       "      <td>-0.160251</td>\n",
       "      <td>1.043895</td>\n",
       "      <td>-0.000749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genome_length  Ratio_1kbp_bins_covered  \\\n",
       "Class                                           \n",
       "1            0.21907                 1.516348   \n",
       "\n",
       "       Ratio_GC-content_uncovered_bins  Ratio_N-content_uncovered_bins  \\\n",
       "Class                                                                    \n",
       "1                            -0.481275                       -0.160251   \n",
       "\n",
       "       Reads_mapped  Total_reads  \n",
       "Class                             \n",
       "1          1.043895    -0.000749  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_interpolated.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016082</td>\n",
       "      <td>-0.06098</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>-0.060841</td>\n",
       "      <td>-0.005691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405132</td>\n",
       "      <td>1.53619</td>\n",
       "      <td>-0.416753</td>\n",
       "      <td>-0.077574</td>\n",
       "      <td>1.532687</td>\n",
       "      <td>0.143355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Genome_length  Ratio_1kbp_bins_covered  \\\n",
       "Class                                           \n",
       "0          -0.016082                 -0.06098   \n",
       "1           0.405132                  1.53619   \n",
       "\n",
       "       Ratio_GC-content_uncovered_bins  Ratio_N-content_uncovered_bins  \\\n",
       "Class                                                                    \n",
       "0                             0.016543                        0.003079   \n",
       "1                            -0.416753                       -0.077574   \n",
       "\n",
       "       Reads_mapped  Total_reads  \n",
       "Class                             \n",
       "0         -0.060841    -0.005691  \n",
       "1          1.532687     0.143355  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2903, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_interpolated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Merging the new and the original data:\n",
    "merged_data = pd.concat((data, data_increased), ignore_index=True) # .sample(frac=1)\n",
    "\n",
    "# 2. Shuffle data \n",
    "from sklearn.utils import shuffle\n",
    "merged_data = shuffle(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genome_length</th>\n",
       "      <th>Ratio_1kbp_bins_covered</th>\n",
       "      <th>Ratio_GC-content_uncovered_bins</th>\n",
       "      <th>Ratio_N-content_uncovered_bins</th>\n",
       "      <th>Reads_mapped</th>\n",
       "      <th>Total_reads</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>-0.398347</td>\n",
       "      <td>-0.211648</td>\n",
       "      <td>-1.529774</td>\n",
       "      <td>-0.167432</td>\n",
       "      <td>-0.113029</td>\n",
       "      <td>-0.619181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>-0.115448</td>\n",
       "      <td>3.012359</td>\n",
       "      <td>-0.487116</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>6.801397</td>\n",
       "      <td>1.447541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>2.645734</td>\n",
       "      <td>2.204056</td>\n",
       "      <td>0.077926</td>\n",
       "      <td>-0.387763</td>\n",
       "      <td>0.512216</td>\n",
       "      <td>-0.405978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>-0.793125</td>\n",
       "      <td>-0.183680</td>\n",
       "      <td>0.829575</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.117813</td>\n",
       "      <td>1.944562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>-0.410265</td>\n",
       "      <td>-0.220521</td>\n",
       "      <td>1.647923</td>\n",
       "      <td>-0.168520</td>\n",
       "      <td>-0.117818</td>\n",
       "      <td>1.944562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Genome_length  Ratio_1kbp_bins_covered  Ratio_GC-content_uncovered_bins  \\\n",
       "2109      -0.398347                -0.211648                        -1.529774   \n",
       "4661      -0.115448                 3.012359                        -0.487116   \n",
       "5297       2.645734                 2.204056                         0.077926   \n",
       "1107      -0.793125                -0.183680                         0.829575   \n",
       "969       -0.410265                -0.220521                         1.647923   \n",
       "\n",
       "      Ratio_N-content_uncovered_bins  Reads_mapped  Total_reads  Class  \n",
       "2109                       -0.167432     -0.113029    -0.619181      0  \n",
       "4661                       -0.017871      6.801397     1.447541      1  \n",
       "5297                       -0.387763      0.512216    -0.405978      1  \n",
       "1107                       -0.168520     -0.117813     1.944562      0  \n",
       "969                        -0.168520     -0.117818     1.944562      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_excel('merged_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5465, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bar plot with ggplot of SMOTE distribution \n",
    "from plotnine import *\n",
    "p = ggplot(merged_data) + geom_bar(aes(x='Class'), fill = \"yellow\", colour = \"blue\")\n",
    "p\n",
    "ggsave(plot = p, filename = 'Final_code_TFM', path = \"/Users/ferdinandosquitieri/Desktop/TFM /ML\")\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       567\n",
      "           1       0.98      1.00      0.99       643\n",
      "\n",
      "    accuracy                           0.99      1210\n",
      "   macro avg       0.99      0.99      0.99      1210\n",
      "weighted avg       0.99      0.99      0.99      1210\n",
      "\n",
      "[[554  13]\n",
      " [  1 642]]\n",
      "0.011570247933884297\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-cf1c5247dfe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpred_smote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'counts'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Defining X and y \n",
    "X = data.drop(['Class'], axis = 1 )\n",
    "y = data['Class']\n",
    "\n",
    "# Resampling with SMOTE algorithm \n",
    "X_smote, y_smote = SMOTE().fit_resample(X, y)\n",
    "\n",
    "# Splitting data \n",
    "xtrain_sm, xtest_sm, ytrain_sm, ytest_sm = train_test_split(X_smote, y_smote, test_size=0.2, random_state=12)\n",
    "\n",
    "# Testing the models with SMOTE \n",
    "smote = SMOTE(random_state=12)\n",
    "pipeline = Pipeline([('smote', smote), ('rfc', RandomForestClassifier(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline.fit(xtrain_sm, ytrain_sm) # fitting  \n",
    "pred_smote = pipeline.predict(xtest_sm) # predicting \n",
    "print(classification_report(ytest_sm, pred_smote)) # results\n",
    "print(confusion_matrix(ytest_sm,pred_smote))\n",
    "print(mean_absolute_error(ytest_sm, pred_smote))\n",
    "sns.countplot(pred_smote)\n",
    "\n",
    "# 2 \n",
    "\n",
    "pipeline_svm = Pipeline([('smote', smote), ('svm', svm.SVC(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_svm.fit(xtrain_sm, ytrain_sm) # fitting  \n",
    "pred_smote = pipeline_svm.predict(xtest_sm) # predicting \n",
    "print(classification_report(ytest_sm, pred_smote)) # results\n",
    "print(confusion_matrix(ytest_sm,pred_smote))\n",
    "print(mean_absolute_error(ytest_sm, pred_smote))\n",
    "sns.countplot(pred_smote)\n",
    "\n",
    "# 3\n",
    "\n",
    "pipeline_lr = Pipeline([('smote', smote), ('lr', LogisticRegression(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_lr.fit(xtrain_sm, ytrain_sm) # fitting  \n",
    "pred_smote = pipeline_lr.predict(xtest_sm) # predicting \n",
    "print(classification_report(ytest_sm, pred_smote)) # results\n",
    "print(confusion_matrix(ytest_sm,pred_smote))\n",
    "print(mean_absolute_error(ytest_sm, pred_smote))\n",
    "sns.countplot(pred_smote)\n",
    "\n",
    "final_results = pd.DataFrame({'Model' : ['Random Forest Classifier', 'SVM', 'Logistic Regression'], 'F1-score' : [0.99, 0.76, 0.75]})\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsmote = pd.DataFrame(pred_smote, columns = ['Class'])\n",
    "predsmote.to_excel('predsmote.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predsmote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dcfe403b8f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Bar plot with ggplot of SMOTE distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotnine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mggplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredsmote\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgeom_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"yellow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predsmote' is not defined"
     ]
    }
   ],
   "source": [
    "# Bar plot with ggplot of SMOTE distribution \n",
    "from plotnine import *\n",
    "ggplot(predsmote) + geom_bar(aes(x='Class'), fill = \"yellow\", colour = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        23\n",
      "           1       0.93      1.00      0.96        25\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.96      0.96      0.96        48\n",
      "weighted avg       0.96      0.96      0.96        48\n",
      "\n",
      "[[21  2]\n",
      " [ 0 25]]\n",
      "0.041666666666666664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        23\n",
      "           1       0.74      0.68      0.71        25\n",
      "\n",
      "    accuracy                           0.71        48\n",
      "   macro avg       0.71      0.71      0.71        48\n",
      "weighted avg       0.71      0.71      0.71        48\n",
      "\n",
      "[[17  6]\n",
      " [ 8 17]]\n",
      "0.2916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.43      0.56        23\n",
      "           1       0.63      0.88      0.73        25\n",
      "\n",
      "    accuracy                           0.67        48\n",
      "   macro avg       0.70      0.66      0.64        48\n",
      "weighted avg       0.70      0.67      0.65        48\n",
      "\n",
      "[[10 13]\n",
      " [ 3 22]]\n",
      "0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  F1-score\n",
       "0  Random Forest Classifier      0.96\n",
       "1                       SVM      0.71\n",
       "2       Logistic Regression      0.73"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cluster Centroids \n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "CC = ClusterCentroids(random_state=12)\n",
    "X_res, y_res = CC.fit_sample(X, y)\n",
    "xtrain_cc, xtest_cc, ytrain_cc, ytest_cc = train_test_split(X_res, y_res, test_size=0.2, random_state=12)\n",
    "\n",
    "# testing \n",
    "\n",
    "pipeline_cc = Pipeline([('CC', CC), ('rfc', RandomForestClassifier(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_cc.fit(xtrain_cc, ytrain_cc) # fitting  \n",
    "pred_cc = pipeline_cc.predict(xtest_cc) # predicting \n",
    "print(classification_report(ytest_cc, pred_cc)) # results\n",
    "print(confusion_matrix(ytest_cc,pred_cc))\n",
    "print(mean_absolute_error(ytest_cc, pred_cc))\n",
    "sns.countplot(pred_cc)\n",
    "\n",
    "# 2 \n",
    "pipeline_cc_svm = Pipeline([('CC', CC), ('svm', svm.SVC(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_cc_svm.fit(xtrain_cc, ytrain_cc) # fitting  \n",
    "pred_cc_svm = pipeline_cc_svm.predict(xtest_cc) # predicting \n",
    "print(classification_report(ytest_cc, pred_cc_svm)) # results\n",
    "print(confusion_matrix(ytest_cc,pred_cc_svm))\n",
    "print(mean_absolute_error(ytest_cc, pred_cc_svm))\n",
    "sns.countplot(pred_cc_svm)\n",
    "\n",
    "# 3 \n",
    "pipeline_cc_lr = Pipeline([('CC', CC), ('lr', LogisticRegression(random_state=12))]) # creating the pipeline we want to use  \n",
    "pipeline_cc_lr.fit(xtrain_cc, ytrain_cc) # fitting  \n",
    "pred_cc_lr = pipeline_cc_lr.predict(xtest_cc) # predicting \n",
    "print(classification_report(ytest_cc, pred_cc_lr)) # results\n",
    "print(confusion_matrix(ytest_cc,pred_cc_lr))\n",
    "print(mean_absolute_error(ytest_cc, pred_cc_lr))\n",
    "sns.countplot(pred_cc_lr)\n",
    "\n",
    "\n",
    "final_results_cc = pd.DataFrame({'Model' : ['Random Forest Classifier', 'SVM', 'Logistic Regression'], 'F1-score' : [0.96, 0.71, 0.73]})\n",
    "\n",
    "final_results_cc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(pred_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x139b8aaf0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(pred_cc_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x139820820>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(pred_cc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predcentroids = pd.DataFrame(pred_cc, columns = ['Class'])\n",
    "predcentroids.to_excel('Predict_cc.xlsx')\n",
    "predcentroids[predcentroids.Class==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ggplot(predcentroids) + geom_bar(aes(x='Class'), fill = \"yellow\", colour = \"blue\")\n",
    "ggsave(plot = p, filename = 'Final_code_TFM', path = \"/Users/ferdinandosquitieri/Desktop/TFM /ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the models on the new data \n",
    "# Defining X and Y \n",
    "X_final = merged_data.drop('Class', axis=1) # data increased with VAE \n",
    "y_final = merged_data['Class']\n",
    "\n",
    "# Split the data \n",
    "xtrain_f, xtest_f, ytrain_f, ytest_f = train_test_split(X_final, y_final, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 \n",
    "from sklearn.ensemble import GradientBoostingClassifier # model 1 \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb # model 2\n",
    "from sklearn.ensemble import AdaBoostClassifier # model 3\n",
    "from sklearn.ensemble import RandomForestClassifier # model 4 \n",
    "from sklearn import svm # model 5 \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression # model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       614\n",
      "           1       0.99      0.98      0.98       479\n",
      "\n",
      "    accuracy                           0.98      1093\n",
      "   macro avg       0.98      0.98      0.98      1093\n",
      "weighted avg       0.98      0.98      0.98      1093\n",
      "\n",
      "[[608   6]\n",
      " [ 11 468]]\n",
      "0.01555352241537054\n",
      "Accuracy :  0.9844464775846294\n",
      "Sensitivity :  0.990228013029316\n",
      "Specificity :  0.9770354906054279\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=12)\n",
    "gbc.fit(xtrain_f,ytrain_f)\n",
    "predict_gbc = gbc.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, predict_gbc))\n",
    "print(confusion_matrix(ytest_f, predict_gbc))\n",
    "\n",
    "# error between data generated and original data \n",
    "print(mean_absolute_error(predict_gbc, ytest_f))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm1 = (confusion_matrix(ytest_f, predict_gbc)) \n",
    "total1 = sum(sum(cm1))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       614\n",
      "           1       0.99      0.99      0.99       479\n",
      "\n",
      "    accuracy                           0.99      1093\n",
      "   macro avg       0.99      0.99      0.99      1093\n",
      "weighted avg       0.99      0.99      0.99      1093\n",
      "\n",
      "[[609   5]\n",
      " [  4 475]]\n",
      "0.008234217749313814\n",
      "Accuracy :  0.9917657822506862\n",
      "Sensitivity :  0.99185667752443\n",
      "Specificity :  0.9916492693110647\n"
     ]
    }
   ],
   "source": [
    "# Model 2 \n",
    "xgb_boost = xgb.XGBClassifier(random_state=12)\n",
    "xgb_boost.fit(xtrain_f, ytrain_f)\n",
    "predict_xgb_boost = xgb_boost.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, predict_xgb_boost))\n",
    "print(confusion_matrix(ytest_f, predict_xgb_boost))\n",
    "\n",
    "# error between data generated and original data \n",
    "print(mean_absolute_error(predict_xgb_boost, ytest_f))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm2 = (confusion_matrix(ytest_f, predict_xgb_boost)) \n",
    "total2 = sum(sum(cm2))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy2 = (cm2[0,0]+cm2[1,1])/total2\n",
    "print ('Accuracy : ', accuracy2)\n",
    "\n",
    "sensitivity2 = cm2[0,0]/(cm2[0,0]+cm2[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "\n",
    "specificity2 = cm2[1,1]/(cm2[1,0]+cm2[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       614\n",
      "           1       0.99      0.98      0.98       479\n",
      "\n",
      "    accuracy                           0.99      1093\n",
      "   macro avg       0.99      0.98      0.99      1093\n",
      "weighted avg       0.99      0.99      0.99      1093\n",
      "\n",
      "[[608   6]\n",
      " [ 10 469]]\n",
      "0.01463860933211345\n",
      "Accuracy :  0.9853613906678865\n",
      "Sensitivity :  0.990228013029316\n",
      "Specificity :  0.9791231732776617\n"
     ]
    }
   ],
   "source": [
    "# Model 3 \n",
    "ada = AdaBoostClassifier(random_state=12)\n",
    "ada.fit(xtrain_f,ytrain_f)\n",
    "predict_ada = ada.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, predict_ada))\n",
    "print(confusion_matrix(ytest_f, predict_ada))\n",
    "\n",
    "# error between data generated and original data \n",
    "print(mean_absolute_error(predict_ada, ytest_f))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm = (confusion_matrix(ytest_f, predict_ada)) \n",
    "total = sum(sum(cm))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy = (cm[0,0]+cm[1,1])/total\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "specificity = cm[1,1]/(cm[1,0]+cm[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       614\n",
      "           1       0.99      0.99      0.99       479\n",
      "\n",
      "    accuracy                           0.99      1093\n",
      "   macro avg       0.99      0.99      0.99      1093\n",
      "weighted avg       0.99      0.99      0.99      1093\n",
      "\n",
      "[[611   3]\n",
      " [  4 475]]\n",
      "Accuracy :  0.9935956084172004\n",
      "Sensitivity :  0.995114006514658\n",
      "Specificity :  0.9916492693110647\n"
     ]
    }
   ],
   "source": [
    "# Model 4 \n",
    "rfc = RandomForestClassifier(n_estimators = 200, random_state = 12)\n",
    "rfc.fit(xtrain_f, ytrain_f)\n",
    "pred_rfc = rfc.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, pred_rfc))\n",
    "print(confusion_matrix(ytest_f, pred_rfc))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm1 = (confusion_matrix(ytest_f, pred_rfc)) \n",
    "total1 = sum(sum(cm1))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0]+cm1[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       614\n",
      "           1       0.90      0.84      0.87       479\n",
      "\n",
      "    accuracy                           0.89      1093\n",
      "   macro avg       0.89      0.88      0.88      1093\n",
      "weighted avg       0.89      0.89      0.89      1093\n",
      "\n",
      "[[567  47]\n",
      " [ 76 403]]\n",
      "Accuracy :  0.8874656907593779\n",
      "Sensitivity :  0.9234527687296417\n",
      "Specificity :  0.8413361169102297\n"
     ]
    }
   ],
   "source": [
    "# Model 5 \n",
    "SVM = svm.SVC(random_state = 12)\n",
    "SVM.fit(xtrain_f, ytrain_f)\n",
    "pred_SVM = SVM.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, pred_SVM)) \n",
    "print(confusion_matrix(ytest_f, pred_SVM)) \n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm2 = (confusion_matrix(ytest_f, pred_SVM)) \n",
    "total2=sum(sum(cm2))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy2=(cm2[0,0]+cm2[1,1])/total2\n",
    "print ('Accuracy : ', accuracy2)\n",
    "\n",
    "sensitivity2 = cm2[0,0]/(cm2[0,0]+cm2[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "\n",
    "specificity2 = cm2[1,1]/(cm2[1,0]+cm2[1,1]) # TN / (TN + FP)\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       614\n",
      "           1       0.87      0.74      0.80       479\n",
      "\n",
      "    accuracy                           0.84      1093\n",
      "   macro avg       0.84      0.83      0.83      1093\n",
      "weighted avg       0.84      0.84      0.84      1093\n",
      "\n",
      "[[561  53]\n",
      " [124 355]]\n",
      "Accuracy :  0.8380603842634949\n",
      "Sensitivity :  0.9136807817589576\n",
      "Specificity :  0.7411273486430062\n"
     ]
    }
   ],
   "source": [
    "# Model 6 \n",
    "logreg = LogisticRegression(solver='lbfgs', random_state = 12)\n",
    "logreg.fit(xtrain_f, ytrain_f)\n",
    "pred_logreg = logreg.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, pred_logreg)) \n",
    "print(confusion_matrix(ytest_f, pred_logreg)) \n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm3 = (confusion_matrix(ytest_f, pred_logreg)) \n",
    "total3=sum(sum(cm3))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy3=(cm3[0,0]+cm3[1,1])/total3\n",
    "print ('Accuracy : ', accuracy3)\n",
    "\n",
    "sensitivity3 = cm3[0,0]/(cm3[0,0]+cm3[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity3 )\n",
    "\n",
    "specificity3 = cm3[1,1]/(cm3[1,0]+cm3[1,1]) # TN / (TN + FP)\n",
    "print('Specificity : ', specificity3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 12, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters tuning - Model 1 \n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV # Grid Search \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "print(gbc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_params = [{'ccp_alpha' : [0.0,0.5,0.7], 'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], 'n_estimators':[100,200,400,600,800] }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ccp_alpha</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.720062</td>\n",
       "      <td>0.049945</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...</td>\n",
       "      <td>0.336986</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336807</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.457903</td>\n",
       "      <td>0.040496</td>\n",
       "      <td>0.008410</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>0.698620</td>\n",
       "      <td>0.705219</td>\n",
       "      <td>0.681174</td>\n",
       "      <td>0.712117</td>\n",
       "      <td>0.708125</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.211356</td>\n",
       "      <td>0.324998</td>\n",
       "      <td>0.011052</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>400</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...</td>\n",
       "      <td>0.928565</td>\n",
       "      <td>0.901622</td>\n",
       "      <td>0.910855</td>\n",
       "      <td>0.881075</td>\n",
       "      <td>0.889028</td>\n",
       "      <td>0.902229</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.558359</td>\n",
       "      <td>0.356853</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>600</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...</td>\n",
       "      <td>0.928565</td>\n",
       "      <td>0.910710</td>\n",
       "      <td>0.915867</td>\n",
       "      <td>0.893463</td>\n",
       "      <td>0.898106</td>\n",
       "      <td>0.909342</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.018112</td>\n",
       "      <td>0.269973</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>800</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...</td>\n",
       "      <td>0.928565</td>\n",
       "      <td>0.910710</td>\n",
       "      <td>0.915867</td>\n",
       "      <td>0.893463</td>\n",
       "      <td>0.898106</td>\n",
       "      <td>0.909342</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.688310</td>\n",
       "      <td>0.020503</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...</td>\n",
       "      <td>0.336986</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336807</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.314400</td>\n",
       "      <td>0.087770</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...</td>\n",
       "      <td>0.336986</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336807</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3.410891</td>\n",
       "      <td>0.524735</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>400</td>\n",
       "      <td>{'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...</td>\n",
       "      <td>0.336986</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336807</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>6.236772</td>\n",
       "      <td>1.037393</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>600</td>\n",
       "      <td>{'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...</td>\n",
       "      <td>0.336986</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336807</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>6.527754</td>\n",
       "      <td>0.957607</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>800</td>\n",
       "      <td>{'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...</td>\n",
       "      <td>0.336986</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336763</td>\n",
       "      <td>0.336807</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.720062      0.049945         0.007997        0.001962   \n",
       "1        1.457903      0.040496         0.008410        0.001611   \n",
       "2        3.211356      0.324998         0.011052        0.001091   \n",
       "3        4.558359      0.356853         0.013491        0.001891   \n",
       "4        6.018112      0.269973         0.015880        0.002042   \n",
       "..            ...           ...              ...             ...   \n",
       "85       0.688310      0.020503         0.005589        0.000582   \n",
       "86       1.314400      0.087770         0.005149        0.000485   \n",
       "87       3.410891      0.524735         0.010030        0.007068   \n",
       "88       6.236772      1.037393         0.007473        0.001439   \n",
       "89       6.527754      0.957607         0.006748        0.002490   \n",
       "\n",
       "   param_ccp_alpha param_learning_rate param_n_estimators  \\\n",
       "0                0              0.0001                100   \n",
       "1                0              0.0001                200   \n",
       "2                0              0.0001                400   \n",
       "3                0              0.0001                600   \n",
       "4                0              0.0001                800   \n",
       "..             ...                 ...                ...   \n",
       "85             0.7                 0.3                100   \n",
       "86             0.7                 0.3                200   \n",
       "87             0.7                 0.3                400   \n",
       "88             0.7                 0.3                600   \n",
       "89             0.7                 0.3                800   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...           0.336986   \n",
       "1   {'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...           0.743494   \n",
       "2   {'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...           0.928565   \n",
       "3   {'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...           0.928565   \n",
       "4   {'ccp_alpha': 0.0, 'learning_rate': 0.0001, 'n...           0.928565   \n",
       "..                                                ...                ...   \n",
       "85  {'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...           0.336986   \n",
       "86  {'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...           0.336986   \n",
       "87  {'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...           0.336986   \n",
       "88  {'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...           0.336986   \n",
       "89  {'ccp_alpha': 0.7, 'learning_rate': 0.3, 'n_es...           0.336986   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.336763           0.336763           0.336763   \n",
       "1            0.698620           0.705219           0.681174   \n",
       "2            0.901622           0.910855           0.881075   \n",
       "3            0.910710           0.915867           0.893463   \n",
       "4            0.910710           0.915867           0.893463   \n",
       "..                ...                ...                ...   \n",
       "85           0.336763           0.336763           0.336763   \n",
       "86           0.336763           0.336763           0.336763   \n",
       "87           0.336763           0.336763           0.336763   \n",
       "88           0.336763           0.336763           0.336763   \n",
       "89           0.336763           0.336763           0.336763   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.336763         0.336807        0.000089               30  \n",
       "1            0.712117         0.708125        0.020455               29  \n",
       "2            0.889028         0.902229        0.016674               28  \n",
       "3            0.898106         0.909342        0.012589               26  \n",
       "4            0.898106         0.909342        0.012589               26  \n",
       "..                ...              ...             ...              ...  \n",
       "85           0.336763         0.336807        0.000089               30  \n",
       "86           0.336763         0.336807        0.000089               30  \n",
       "87           0.336763         0.336807        0.000089               30  \n",
       "88           0.336763         0.336807        0.000089               30  \n",
       "89           0.336763         0.336807        0.000089               30  \n",
       "\n",
       "[90 rows x 16 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12)\n",
    "tuned_gbc = GridSearchCV(GradientBoostingClassifier(), tuned_params, cv = 5, scoring = 'f1_macro')\n",
    "tuned_gbc.fit(xtrain, ytrain)\n",
    "tuned_gbc.predict(xtest)\n",
    "tuned_gbc.cv_results_\n",
    "\n",
    "gbc_table = pd.DataFrame(tuned_gbc.cv_results_)\n",
    "gbc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gbc.best_score_ # 0.9890390787112274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 \n",
    "print('Parameters currently in use:\\n')\n",
    "print(xgb_boost.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_params_xgb = [{'base_score' : [0.0,0.5,0.7], 'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], 'n_estimators':[100,200,400,600,800] }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "tuned_xgb = GridSearchCV(xgb.XGBClassifier(random_state=12), tuned_params, cv = 5, scoring = 'f1_macro')\n",
    "tuned_xgb.fit(xtrain, ytrain)\n",
    "tuned_xgb.cv_results_\n",
    "\n",
    "xgb_table = pd.DataFrame(tuned_xgb.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 \n",
    "print('Parameters currently in use:\\n')\n",
    "print(ada.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_ada_params = [{'algorithm' : ['SAMME', 'SAMME.R'], 'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], 'n_estimators':[100,200,400,600,800] }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "tuned_ada= GridSearchCV(AdaBoostClassifier(random_state=12), tuned_ada_params, cv = 5, scoring = 'f1_macro')\n",
    "tuned_ada.fit(xtrain, ytrain)\n",
    "tuned_ada.cv_results_\n",
    "\n",
    "ada_table = pd.DataFrame(tuned_ada.cv_results_)\n",
    "ada_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 \n",
    "print('Parameters currently in use:\\n')\n",
    "print(rfc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_params_rfc = [{'n_estimators' : [100,500,800], 'oob_score' : [False, True], 'ccp_alpha' : [0.0, 0.5, 0.7], 'criterion' : ['gini', 'entropy']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc = GridSearchCV(RandomForestClassifier(random_state = 12), tuned_params_rfc, cv = 5, scoring = 'f1_macro')\n",
    "tuned_rfc.fit(xtrain, ytrain)\n",
    "tuned_rfc.cv_results_\n",
    "\n",
    "rfc_table = pd.DataFrame(tuned_rfc.cv_results_)\n",
    "rfc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5 \n",
    "print('Parameters currently in use:\\n')\n",
    "print(SVM.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_svm = [{'kernel' : ['rbf'], 'gamma' : [1e-3, 1e-4], \n",
    "                    'C' : [1,10,100,1000]},\n",
    "                   {'kernel' : ['linear'], 'C' : [1,10,100,1000]}]\n",
    "\n",
    "np.random.seed(123)\n",
    "tuned_svm = GridSearchCV(svm.SVC(), tuned_svm, cv = 5, scoring = 'f1_macro')\n",
    "tuned_svm.fit(xtrain,ytrain) #testing \n",
    "tuned_svm.best_params_\n",
    "tuned_svm.cv_results_\n",
    "\n",
    "svm_table = pd.DataFrame(tuned_svm.cv_results_)\n",
    "svm_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6 \n",
    "print('Parameters currently in use:\\n')\n",
    "print(logreg.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_logreg = [{'penalty' : ['l5', 'l1', 'l2', 'l20'],  \n",
    "                    'C' : [1,10,100,1000],\n",
    "               'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}]\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "tuned_logreg = GridSearchCV(LogisticRegression(), tuned_logreg, cv = 5, scoring = 'f1_macro')\n",
    "tuned_logreg.fit(xtrain,ytrain) #testing \n",
    "tuned_logreg.cv_results_\n",
    "\n",
    "logreg_table = pd.DataFrame(tuned_logreg.cv_results_)\n",
    "logreg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'SVM' : {\n",
    "        'Model': svm.SVC(random_state = 1),\n",
    "        'Params': {\n",
    "            'C' : [1,10,100,1000],\n",
    "            'gamma' : [1e-3, 1e-4], \n",
    "        }\n",
    "    },\n",
    "    'Random_forest' : {\n",
    "        'Model': RandomForestClassifier(random_state = 1),\n",
    "        'Params': {\n",
    "            'n_estimators' : [100,500,800],\n",
    "            'oob_score' : [False, True]\n",
    "        }\n",
    "    },\n",
    "    'Logistic_regression' : {\n",
    "        'Model': LogisticRegression(random_state = 1),\n",
    "        'Params': {\n",
    "        'C' : [1,10,100,1000],\n",
    "            'penalty' : ['l1', 'l2'],\n",
    "            'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }\n",
    "},\n",
    "    'Gradient_Boosting' : {\n",
    "        'Model' : GradientBoostingClassifier(random_state = 1),\n",
    "        'Params' : {\n",
    "            'ccp_alpha' : [0.0,0.5,0.7], \n",
    "            'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], \n",
    "            'n_estimators':[100,200,400,600,800]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'XGB_Boosting' : {\n",
    "        'Model' : xgb.XGBClassifier(random_state = 1),\n",
    "        'Params' : {\n",
    "            'base_score' : [0.0,0.5,0.7], \n",
    "            'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], \n",
    "            'n_estimators':[100,200,400,600,800]  \n",
    "        }\n",
    "    }, \n",
    "    \n",
    "    'Ada_Boosting' : {\n",
    "        'Model' : AdaBoostClassifier(random_state = 1),\n",
    "        'Params' : {\n",
    "            'algorithm' : ['SAMME', 'SAMME.R'], \n",
    "            'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3], \n",
    "            'n_estimators':[100,200,400,600,800]  \n",
    "        }\n",
    "    } \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "np.random.seed(12)\n",
    "for model_name, mp in model_params.items():\n",
    "    final_model = GridSearchCV(mp['Model'], mp['Params'], cv=5, return_train_score=False, scoring='f1_micro')\n",
    "    final_model.fit(X_final,y_final)\n",
    "    scores.append({\n",
    "        'Model': model_name,\n",
    "        'Best score' : final_model.best_score_,\n",
    "        'Best params': final_model.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params_table = pd.DataFrame(scores,columns=['Model', 'Best score', 'Best params']).sort_values(by=['Best score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params_table.iloc[1,2] # to check the best parameters of the XGB_Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = xgb.XGBClassifier(base_score = 0.7, learning_rate = 0.3, n_estimators = 800, random_state=12)\n",
    "final_model.fit(xtrain_f, ytrain_f)\n",
    "final_predict = final_model.predict(xtest_f)\n",
    "\n",
    "print(classification_report(ytest_f, final_predict))\n",
    "print(confusion_matrix(ytest_f, final_predict))\n",
    "\n",
    "# Calculating Sensitivity and Specificity from confusion matrix : \n",
    "cm2 = (confusion_matrix(ytest_f, final_predict)) \n",
    "total2 = sum(sum(cm2))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy2 = (cm2[0,0]+cm2[1,1])/total2\n",
    "print ('Accuracy : ', accuracy2)\n",
    "\n",
    "sensitivity2 = cm2[0,0]/(cm2[0,0]+cm2[0,1]) #  TP / (TP+FN)\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "\n",
    "specificity2 = cm2[1,1]/(cm2[1,0]+cm2[1,1])  # TN / (TN + FP)\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-c84f1101b3b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtitles_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitles_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtest_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0max_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "titles_options = [('Final Model')]\n",
    "for title in titles_options:\n",
    "    disp = plot_confusion_matrix(final_model, xtest_f, ytest_f)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(final_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pickle object of the final model : \n",
    "import pickle    \n",
    "\n",
    "#save the model\n",
    "pickle.dump(final_model, open('final_model.sav', 'wb'))\n",
    "# save the scaler\n",
    "pickle.dump(sc, open('scaler.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
